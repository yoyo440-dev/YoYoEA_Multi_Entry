{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc7510b3",
   "metadata": {},
   "source": [
    "# StateLog × TradeLog 解析テンプレート\n",
    "- `analysis/env_data` と `analysis/bt_results` に配置した CSV を読み込み、環境指標とBT結果を突き合わせるためのノートです。\n",
    "- `merged_trades` DataFrame を作成しておけば、帯域別・時間別の集計を容易に反復できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc43fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from functools import lru_cache\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "def find_workspace_root(marker='analysis'):\n",
    "    current = Path.cwd().resolve()\n",
    "    for candidate in [current, *current.parents]:\n",
    "        if (candidate / marker).is_dir():\n",
    "            return candidate\n",
    "    raise FileNotFoundError(\"'{}' directory not found from {}\".format(marker, current))\n",
    "\n",
    "WORKSPACE_ROOT = find_workspace_root()\n",
    "DATA_ROOT = WORKSPACE_ROOT / 'analysis'\n",
    "ENV_DIR = DATA_ROOT / 'env_data'\n",
    "BT_DIR = DATA_ROOT / 'bt_results'\n",
    "\n",
    "def list_csv(directory, pattern='*.csv'):\n",
    "    return sorted(directory.glob(pattern))\n",
    "\n",
    "print('Workspace root:', WORKSPACE_ROOT)\n",
    "print('Env dir:', ENV_DIR)\n",
    "print('BT dir:', BT_DIR)\n",
    "print('Detected env csv:', len(list_csv(ENV_DIR)))\n",
    "print('Detected bt csv:', len(list_csv(BT_DIR, 'TradeLog_*.csv')))\n",
    "\n",
    "def resolve_bt_path(bt_name=None, pattern='TradeLog_*.csv'):\n",
    "    if bt_name:\n",
    "        candidate = BT_DIR / bt_name\n",
    "        if candidate.exists():\n",
    "            return candidate\n",
    "        raise FileNotFoundError(f\"{candidate} が存在しません\")\n",
    "    files = list_csv(BT_DIR, pattern)\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"BT_DIR に {pattern} が見つかりません\")\n",
    "    return files[-1]\n",
    "\n",
    "def load_bt_dataframe(bt_name=None):\n",
    "    bt_path = resolve_bt_path(bt_name)\n",
    "    df = pd.read_csv(bt_path)\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'].str.replace('.', '-', regex=False))\n",
    "    return df, bt_path\n",
    "\n",
    "@lru_cache(maxsize=1)\n",
    "def build_env_index():\n",
    "    env_map = {}\n",
    "    for csv_path in list_csv(ENV_DIR, '*.csv'):\n",
    "        digits = ''.join(filter(str.isdigit, csv_path.stem))\n",
    "        if len(digits) < 8:\n",
    "            continue\n",
    "        key = digits[-8:]\n",
    "        env_map.setdefault(key, []).append(csv_path)\n",
    "    return {k: tuple(v) for k, v in env_map.items()}\n",
    "\n",
    "def load_env_frames(date_keys, sep=';'):\n",
    "    env_map = build_env_index()\n",
    "    frames = []\n",
    "    missing = []\n",
    "    for key in date_keys:\n",
    "        paths = env_map.get(key)\n",
    "        if not paths:\n",
    "            missing.append(key)\n",
    "            continue\n",
    "        day_frames = [pd.read_csv(path, sep=sep) for path in paths]\n",
    "        env_part = pd.concat(day_frames, ignore_index=True)\n",
    "        env_part['bar_time'] = pd.to_datetime(env_part['bar_time'].str.replace('.', '-', regex=False))\n",
    "        frames.append(env_part)\n",
    "    return frames, missing\n",
    "\n",
    "def concat_env_frames(frames):\n",
    "    if not frames:\n",
    "        raise ValueError('frames is empty')\n",
    "    return pd.concat(frames, ignore_index=True).sort_values('bar_time')\n",
    "\n",
    "def merge_entries_with_env(bt_df, env_df, tolerance='5min', direction='backward', timeframe_filter=None):\n",
    "    entries = bt_df[bt_df['event'] == 'ENTRY'].copy()\n",
    "    if 'timestamp' not in entries.columns:\n",
    "        raise KeyError('BT CSVに timestamp 列がありません')\n",
    "\n",
    "    env_part = env_df.copy()\n",
    "    if 'timestamp' in env_part.columns:\n",
    "        env_part = env_part.rename(columns={'timestamp': 'env_timestamp'})\n",
    "    if 'bar_time' not in env_part.columns:\n",
    "        raise KeyError('環境CSVに bar_time 列がありません')\n",
    "\n",
    "    if 'symbol' in entries.columns and 'symbol' in env_part.columns:\n",
    "        symbols = entries['symbol'].dropna().unique().tolist()\n",
    "        env_part = env_part[env_part['symbol'].isin(symbols)]\n",
    "\n",
    "    if timeframe_filter and 'timeframe' in env_part.columns:\n",
    "        env_part = env_part[env_part['timeframe'] == timeframe_filter]\n",
    "\n",
    "    if 'symbol' in entries.columns and 'symbol' in env_part.columns:\n",
    "        entries = entries.sort_values(['symbol', 'timestamp'])\n",
    "        env_sorted = env_part.sort_values(['symbol', 'bar_time'])\n",
    "        merged = pd.merge_asof(entries, env_sorted, left_on='timestamp', right_on='bar_time',\n",
    "                               by='symbol', direction=direction, tolerance=pd.Timedelta(tolerance))\n",
    "        return merged\n",
    "\n",
    "    entries = entries.sort_values('timestamp')\n",
    "    env_sorted = env_part.sort_values('bar_time')\n",
    "    merged = pd.merge_asof(entries, env_sorted, left_on='timestamp', right_on='bar_time',\n",
    "                           direction=direction, tolerance=pd.Timedelta(tolerance))\n",
    "    return merged\n",
    "\n",
    "def build_entry_exit(bt_df, merged):\n",
    "    required = {'ticket', 'strategy'}\n",
    "    missing = required - set(bt_df.columns)\n",
    "    if missing:\n",
    "        raise KeyError(f\"BT CSVに必要な列がありません: {missing}\")\n",
    "    exit_columns = ['ticket', 'net', 'pips', 'timestamp']\n",
    "    if 'exit_reason' in bt_df.columns:\n",
    "        exit_columns.append('exit_reason')\n",
    "    exits = bt_df[bt_df['event'] == 'EXIT'][exit_columns].copy()\n",
    "    exits = exits.rename(columns={'timestamp': 'exit_timestamp', 'net': 'exit_net', 'pips': 'exit_pips'})\n",
    "\n",
    "    merged_entries = merged.copy()\n",
    "    redundant = [col for col in ('exit_reason', 'exit_timestamp', 'exit_net', 'exit_pips') if col in merged_entries.columns]\n",
    "    if redundant:\n",
    "        merged_entries = merged_entries.drop(columns=redundant)\n",
    "\n",
    "    entry_exit = merged_entries.merge(exits, on='ticket', how='left')\n",
    "\n",
    "    for col in ['atr_entry', 'adx_entry', 'donchian_width']:\n",
    "        if col not in entry_exit.columns:\n",
    "            entry_exit[col] = pd.NA\n",
    "\n",
    "    width_candidates = [\n",
    "        'donchian_width', 'donchian_width_x', 'donchian_width_entry', 'donchian_width_bt',\n",
    "        'donchian_width_y', 'donchian_width_env', 'donchian_width_exit'\n",
    "    ]\n",
    "    width_series = None\n",
    "    for col in width_candidates:\n",
    "        if col in entry_exit.columns:\n",
    "            data = entry_exit[col]\n",
    "            width_series = data.copy() if width_series is None else width_series.fillna(data)\n",
    "    if width_series is None:\n",
    "        width_series = pd.Series(pd.NA, index=entry_exit.index)\n",
    "    entry_exit['donchian_width'] = pd.to_numeric(width_series, errors='coerce')\n",
    "\n",
    "    numeric_cols = ['atr_entry', 'adx_entry', 'donchian_width', 'exit_net', 'exit_pips']\n",
    "    for col in numeric_cols:\n",
    "        if col in entry_exit.columns:\n",
    "            entry_exit[col] = pd.to_numeric(entry_exit[col], errors='coerce')\n",
    "\n",
    "    if 'exit_reason' in entry_exit.columns:\n",
    "        entry_exit['exit_reason'] = entry_exit['exit_reason'].fillna('UNKNOWN')\n",
    "    else:\n",
    "        entry_exit['exit_reason'] = 'UNKNOWN'\n",
    "\n",
    "    return entry_exit\n",
    "\n",
    "def ensure_entry_exit():\n",
    "    notebook_globals = globals()\n",
    "    entry_exit = notebook_globals.get('entry_exit')\n",
    "    if entry_exit is not None:\n",
    "        return entry_exit\n",
    "    bt_df = notebook_globals.get('bt_df')\n",
    "    merged = notebook_globals.get('merged')\n",
    "    if bt_df is None or merged is None:\n",
    "        raise NameError('entry_exit を生成するには bt_df と merged が必要です。')\n",
    "    entry_exit = build_entry_exit(bt_df, merged)\n",
    "    notebook_globals['entry_exit'] = entry_exit\n",
    "    return entry_exit\n",
    "\n",
    "ATR_BUCKET_BINS = [0, 0.10, 0.14, 0.18, float('inf')]\n",
    "ATR_BUCKET_LABELS = ['0.00-0.10','0.10-0.14','0.14-0.18','0.18+']\n",
    "ADX_BUCKET_BINS = [0, 25, 30, float('inf')]\n",
    "ADX_BUCKET_LABELS = ['<=25','25-30','30+']\n",
    "DONCHIAN_BUCKET_BINS = [0, 0.25, float('inf')]\n",
    "DONCHIAN_BUCKET_LABELS = ['low','high']\n",
    "\n",
    "CURRENT_NOTEBOOK_PATH = WORKSPACE_ROOT / Path('analysis/notebooks/state_bt_analysis.ipynb')\n",
    "OUTPUT_NOTEBOOK_DIR = CURRENT_NOTEBOOK_PATH.parent\n",
    "\n",
    "pd.set_option('display.max_columns', 40)\n",
    "pd.set_option('display.width', 120)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8115871",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==== 解析設定 ====\n",
    "BT_FILE_NAME = None  # 解析対象のBTログ。最新ファイルを使う場合は None のまま\n",
    "ENV_SEPARATOR = ';'  # StateLog CSV の区切り文字\n",
    "MERGE_TOLERANCE = '5min'  # ENTRY時刻と環境データを突き合わせる許容時間\n",
    "MERGE_DIRECTION = 'backward'  # merge_asofの方向（futureリーク回避のため backward 推奨）\n",
    "ENV_TIMEFRAME_FILTER = None  # 例: 'M15'（Envに複数timeframeが混在する場合は指定推奨）\n",
    "SAMPLE_PREVIEW_ROWS = 5  # ロード直後に表示するサンプル行数\n",
    "\n",
    "pd.set_option('display.max_columns', 40)\n",
    "pd.set_option('display.width', 120)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f3eba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==== BT/環境データの読み込み ====\n",
    "bt_df, bt_path = load_bt_dataframe(BT_FILE_NAME)\n",
    "print(f'Using BT file: {bt_path.name} ({len(bt_df)} rows)')\n",
    "\n",
    "date_keys = sorted(bt_df['timestamp'].dt.strftime('%Y%m%d').unique())\n",
    "env_frames, missing_dates = load_env_frames(tuple(date_keys), sep=ENV_SEPARATOR)\n",
    "if missing_dates:\n",
    "    print('[WARN] 環境ファイル未検出日:', ', '.join(missing_dates))\n",
    "\n",
    "if not env_frames:\n",
    "    raise FileNotFoundError('BT対象日に対応する環境ファイルが見つかりません')\n",
    "\n",
    "env_df = concat_env_frames(env_frames)\n",
    "print('Loaded env rows:', len(env_df), 'from', len(env_frames), '日分')\n",
    "\n",
    "merged = merge_entries_with_env(bt_df, env_df, tolerance=MERGE_TOLERANCE, direction=MERGE_DIRECTION, timeframe_filter=ENV_TIMEFRAME_FILTER)\n",
    "print('merged rows', len(merged))\n",
    "preview_cols = [col for col in ['timestamp', 'bar_time', 'symbol', 'strategy', 'atr_entry', 'adx_entry', 'donchian_width', 'session'] if col in merged.columns]\n",
    "if preview_cols:\n",
    "    sample = merged[preview_cols].head(SAMPLE_PREVIEW_ROWS).fillna('-')\n",
    "    print('--- merged sample ---')\n",
    "    print(sample.to_string(index=False))\n",
    "else:\n",
    "    print('preview columns not available')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023149d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==== ENTRY環境とEXIT結果を結合 ====\n",
    "entry_exit = build_entry_exit(bt_df, merged)\n",
    "print('combined rows', len(entry_exit))\n",
    "preview_cols = [col for col in ['timestamp', 'bar_time', 'strategy', 'atr_entry', 'adx_entry', 'exit_reason', 'exit_net'] if col in entry_exit.columns]\n",
    "if preview_cols:\n",
    "    sample = entry_exit[preview_cols].head(SAMPLE_PREVIEW_ROWS).fillna('-')\n",
    "    print('--- entry/exit sample ---')\n",
    "    print(sample.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b10db6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== セッション×指標サマリ ====\n",
    "entry_exit = ensure_entry_exit()\n",
    "entry_exit['exit_net'] = pd.to_numeric(entry_exit['exit_net'], errors='coerce')\n",
    "entry_exit = entry_exit.dropna(subset=['exit_net']).copy()\n",
    "\n",
    "if 'session' not in entry_exit.columns:\n",
    "    entry_exit['session'] = 'UNKNOWN'\n",
    "else:\n",
    "    entry_exit['session'] = entry_exit['session'].fillna('UNKNOWN')\n",
    "\n",
    "if 'strategy' not in entry_exit.columns:\n",
    "    raise KeyError('strategy 列が存在しません')\n",
    "\n",
    "summary_cols = ['session', 'strategy']\n",
    "\n",
    "\n",
    "def summarize(group):\n",
    "    total = len(group)\n",
    "    wins = group['exit_net'] > 0\n",
    "    losses = group['exit_net'] < 0\n",
    "    gross_profit = group.loc[wins, 'exit_net'].sum()\n",
    "    gross_loss = group.loc[losses, 'exit_net'].sum()\n",
    "    profit_factor = gross_profit / abs(gross_loss) if gross_loss != 0 else float('inf')\n",
    "    win_rate = wins.sum() / total if total else float('nan')\n",
    "    avg_win = group.loc[wins, 'exit_net'].mean() if wins.any() else 0.0\n",
    "    avg_loss = group.loc[losses, 'exit_net'].mean() if losses.any() else 0.0\n",
    "    expectancy = group['exit_net'].mean()\n",
    "    return pd.Series({\n",
    "        'Trades': total,\n",
    "        'Wins': int(wins.sum()),\n",
    "        'Losses': int(losses.sum()),\n",
    "        'Win Rate (%)': win_rate * 100,\n",
    "        'PF': profit_factor,\n",
    "        'Avg Win': avg_win,\n",
    "        'Avg Loss': avg_loss,\n",
    "        'Expectancy': expectancy,\n",
    "    })\n",
    "\n",
    "session_strategy = (\n",
    "    entry_exit.groupby(summary_cols, group_keys=False, observed=False)\n",
    "    .apply(summarize)\n",
    "    .reset_index()\n",
    "    .sort_values(['session', 'strategy'])\n",
    ")\n",
    "\n",
    "format_dict = {\n",
    "    'Win Rate (%)': '{:.2f}',\n",
    "    'PF': '{:.2f}',\n",
    "    'Avg Win': '{:.2f}',\n",
    "    'Avg Loss': '{:.2f}',\n",
    "    'Expectancy': '{:.2f}',\n",
    "}\n",
    "\n",
    "session_strategy.style.format(format_dict).set_table_attributes('style=\"table-layout: fixed; width: 100%;\"')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d126f1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== ATR×ADX帯域の損益集計 ====\n",
    "entry_exit = ensure_entry_exit()\n",
    "attr = entry_exit.dropna(subset=['atr_entry','strategy','exit_net']).copy()\n",
    "adx_candidates = []\n",
    "if 'adx_entry' in attr.columns:\n",
    "    adx_candidates.append(attr['adx_entry'])\n",
    "if 'adx14' in attr.columns:\n",
    "    adx_candidates.append(attr['adx14'])\n",
    "if not adx_candidates:\n",
    "    raise ValueError('ADX列が見つかりません (adx_entry/ adx14)')\n",
    "adx_value = None\n",
    "for series in adx_candidates:\n",
    "    adx_value = series if adx_value is None else adx_value.combine_first(series)\n",
    "attr['adx_value'] = adx_value\n",
    "attr = attr.dropna(subset=['adx_value'])\n",
    "if attr.empty:\n",
    "    raise ValueError('ATR/ADX/strategy が不足しています')\n",
    "attr['atr_bucket'] = pd.cut(attr['atr_entry'].astype(float), bins=ATR_BUCKET_BINS, labels=ATR_BUCKET_LABELS, right=False)\n",
    "attr['adx_bucket'] = pd.cut(attr['adx_value'].astype(float), bins=ADX_BUCKET_BINS, labels=ADX_BUCKET_LABELS, right=False)\n",
    "metrics = attr.pivot_table(index=['atr_bucket','adx_bucket'], columns='strategy', values='exit_net', aggfunc=['count','sum','mean'], fill_value=0, observed=False)\n",
    "idx = pd.IndexSlice\n",
    "if 'count' in metrics.columns.get_level_values(0):\n",
    "    metrics.loc[:, idx['count', :]] = metrics.loc[:, idx['count', :]].astype(int)\n",
    "if 'sum' in metrics.columns.get_level_values(0):\n",
    "    metrics.loc[:, idx['sum', :]] = metrics.loc[:, idx['sum', :]].round(2)\n",
    "if 'mean' in metrics.columns.get_level_values(0):\n",
    "    metrics.loc[:, idx['mean', :]] = metrics.loc[:, idx['mean', :]].round(2)\n",
    "metrics.style     .format('{:.2f}', subset=idx[:, idx[['sum','mean'], :]])     .format('{:d}', subset=idx[:, idx[['count'], :]])     .set_table_attributes('style=\"table-layout: fixed; width: 100%;\"')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5bb47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== ATR帯×期間ばらつきサマリ ====\n",
    "entry_exit = ensure_entry_exit()\n",
    "exits = entry_exit.dropna(subset=['atr_entry','exit_net']).copy()\n",
    "if exits.empty:\n",
    "    raise ValueError('EXIT結果が存在しません')\n",
    "\n",
    "# 期間キー（優先: exit_timestamp -> timestamp -> bar_time）\n",
    "ts_col = None\n",
    "for cand in ('exit_timestamp', 'timestamp', 'bar_time'):\n",
    "    if cand in exits.columns:\n",
    "        ts_col = cand\n",
    "        break\n",
    "if ts_col is None:\n",
    "    raise KeyError('時刻列が見つかりません (exit_timestamp/timestamp/bar_time)')\n",
    "\n",
    "exits[ts_col] = pd.to_datetime(exits[ts_col])\n",
    "exits['period'] = exits[ts_col].dt.to_period('M').dt.to_timestamp()\n",
    "exits['atr_bucket'] = pd.cut(exits['atr_entry'].astype(float), bins=ATR_BUCKET_BINS, labels=ATR_BUCKET_LABELS, right=False)\n",
    "\n",
    "def summarize_period(g):\n",
    "    total = len(g)\n",
    "    wins = g['exit_net'] > 0\n",
    "    losses = g['exit_net'] < 0\n",
    "    gross_profit = g.loc[wins, 'exit_net'].sum()\n",
    "    gross_loss = g.loc[losses, 'exit_net'].sum()\n",
    "    pf = gross_profit / abs(gross_loss) if gross_loss != 0 else float('inf')\n",
    "    win_rate = wins.sum() / total if total else float('nan')\n",
    "    expectancy = g['exit_net'].mean()\n",
    "    return pd.Series({\n",
    "        'trades': total,\n",
    "        'win_rate_pct': win_rate * 100,\n",
    "        'pf': pf,\n",
    "        'expectancy': expectancy,\n",
    "        'sum_net': g['exit_net'].sum(),\n",
    "    })\n",
    "\n",
    "period_stats = (\n",
    "    exits.groupby(['atr_bucket','period'], observed=False)\n",
    "    .apply(summarize_period)\n",
    "    .reset_index()\n",
    "    .sort_values(['atr_bucket','period'])\n",
    ")\n",
    "\n",
    "# 期間方向の分位点でばらつきを確認\n",
    "band_quantiles = period_stats.groupby('atr_bucket', observed=False).agg({\n",
    "    'trades': ['mean', 'median'],\n",
    "    'win_rate_pct': ['median', lambda s: s.quantile(0.25), lambda s: s.quantile(0.75)],\n",
    "    'pf': ['median', lambda s: s.quantile(0.25), lambda s: s.quantile(0.75)],\n",
    "    'expectancy': ['median', lambda s: s.quantile(0.25), lambda s: s.quantile(0.75)],\n",
    "})\n",
    "band_quantiles.columns = [\n",
    "    'trades_mean', 'trades_median',\n",
    "    'win_rate_median', 'win_rate_p25', 'win_rate_p75',\n",
    "    'pf_median', 'pf_p25', 'pf_p75',\n",
    "    'expectancy_median', 'expectancy_p25', 'expectancy_p75',\n",
    "]\n",
    "band_quantiles = band_quantiles.round(2)\n",
    "print('--- period_stats sample ---')\n",
    "print(period_stats.head())\n",
    "band_quantiles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743ddc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==== ATR帯×期間ばらつき（戦略別） ====\n",
    "entry_exit = ensure_entry_exit()\n",
    "exits = entry_exit.dropna(subset=['atr_entry','exit_net','strategy']).copy()\n",
    "if exits.empty:\n",
    "    raise ValueError('EXIT結果が存在しません')\n",
    "\n",
    "# 期間キー（優先: exit_timestamp -> timestamp -> bar_time）\n",
    "ts_col = None\n",
    "for cand in ('exit_timestamp', 'timestamp', 'bar_time'):\n",
    "    if cand in exits.columns:\n",
    "        ts_col = cand\n",
    "        break\n",
    "if ts_col is None:\n",
    "    raise KeyError('時刻列が見つかりません (exit_timestamp/timestamp/bar_time)')\n",
    "\n",
    "exits[ts_col] = pd.to_datetime(exits[ts_col])\n",
    "exits['period'] = exits[ts_col].dt.to_period('M').dt.to_timestamp()\n",
    "exits['atr_bucket'] = pd.cut(exits['atr_entry'].astype(float), bins=ATR_BUCKET_BINS, labels=ATR_BUCKET_LABELS, right=False)\n",
    "\n",
    "\n",
    "def summarize_period(g):\n",
    "    total = len(g)\n",
    "    wins = g['exit_net'] > 0\n",
    "    losses = g['exit_net'] < 0\n",
    "    gross_profit = g.loc[wins, 'exit_net'].sum()\n",
    "    gross_loss = g.loc[losses, 'exit_net'].sum()\n",
    "    pf = gross_profit / abs(gross_loss) if gross_loss != 0 else float('inf')\n",
    "    win_rate = wins.sum() / total if total else float('nan')\n",
    "    expectancy = g['exit_net'].mean()\n",
    "    return pd.Series({\n",
    "        'trades': total,\n",
    "        'win_rate_pct': win_rate * 100,\n",
    "        'pf': pf,\n",
    "        'expectancy': expectancy,\n",
    "        'sum_net': g['exit_net'].sum(),\n",
    "    })\n",
    "\n",
    "period_stats_s = (\n",
    "    exits.groupby(['atr_bucket','strategy','period'], observed=False)\n",
    "    .apply(summarize_period)\n",
    "    .reset_index()\n",
    "    .sort_values(['atr_bucket','strategy','period'])\n",
    ")\n",
    "\n",
    "band_quantiles_s = period_stats_s.groupby(['atr_bucket','strategy'], observed=False).agg({\n",
    "    'trades': ['mean', 'median'],\n",
    "    'win_rate_pct': ['median', lambda s: s.quantile(0.25), lambda s: s.quantile(0.75)],\n",
    "    'pf': ['median', lambda s: s.quantile(0.25), lambda s: s.quantile(0.75)],\n",
    "    'expectancy': ['median', lambda s: s.quantile(0.25), lambda s: s.quantile(0.75)],\n",
    "})\n",
    "band_quantiles_s.columns = [\n",
    "    'trades_mean', 'trades_median',\n",
    "    'win_rate_median', 'win_rate_p25', 'win_rate_p75',\n",
    "    'pf_median', 'pf_p25', 'pf_p75',\n",
    "    'expectancy_median', 'expectancy_p25', 'expectancy_p75',\n",
    "]\n",
    "band_quantiles_s = band_quantiles_s.round(2)\n",
    "print('--- period_stats_s sample ---')\n",
    "print(period_stats_s.head())\n",
    "band_quantiles_s\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de615553",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==== ATR×Donchian帯域の損益集計 ====\n",
    "entry_exit = ensure_entry_exit()\n",
    "don = entry_exit.dropna(subset=['atr_entry','donchian_width','strategy','exit_net']).copy()\n",
    "if don.empty:\n",
    "    raise ValueError('ATR/Donchian/strategy が不足しています')\n",
    "don['atr_bucket'] = pd.cut(don['atr_entry'].astype(float), bins=ATR_BUCKET_BINS, labels=ATR_BUCKET_LABELS, right=False)\n",
    "don['donchian_bucket'] = pd.cut(don['donchian_width'], bins=DONCHIAN_BUCKET_BINS, labels=DONCHIAN_BUCKET_LABELS, right=False)\n",
    "metrics_d = don.pivot_table(index=['atr_bucket','donchian_bucket'], columns='strategy', values='exit_net', aggfunc=['count','sum','mean'], fill_value=0, observed=False)\n",
    "idx = pd.IndexSlice\n",
    "if 'count' in metrics_d.columns.get_level_values(0):\n",
    "    metrics_d.loc[:, idx['count', :]] = metrics_d.loc[:, idx['count', :]].astype(int)\n",
    "if 'sum' in metrics_d.columns.get_level_values(0):\n",
    "    metrics_d.loc[:, idx['sum', :]] = metrics_d.loc[:, idx['sum', :]].round(2)\n",
    "if 'mean' in metrics_d.columns.get_level_values(0):\n",
    "    metrics_d.loc[:, idx['mean', :]] = metrics_d.loc[:, idx['mean', :]].round(2)\n",
    "metrics_d.style     .format('{:.2f}', subset=idx[:, idx[['sum','mean'], :]])     .format('{:d}', subset=idx[:, idx[['count'], :]])     .set_table_attributes('style=\"table-layout: fixed; width: 100%;\"')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83afdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== ATR帯×戦略×EXIT理由の損益 ====\n",
    "entry_exit = ensure_entry_exit()\n",
    "if 'exit_reason' not in entry_exit.columns:\n",
    "    entry_exit['exit_reason'] = 'UNKNOWN'\n",
    "exits = entry_exit.dropna(subset=['atr_entry','strategy','exit_net']).copy()\n",
    "if exits.empty:\n",
    "    raise ValueError('EXIT結果が存在しません')\n",
    "exits['exit_reason'] = exits['exit_reason'].fillna('UNKNOWN')\n",
    "exits['atr_bucket'] = pd.cut(exits['atr_entry'].astype(float), bins=ATR_BUCKET_BINS, labels=ATR_BUCKET_LABELS, right=False)\n",
    "exit_summary = (\n",
    "    exits.groupby(['atr_bucket','strategy','exit_reason'], observed=False)\n",
    "    .agg(count=('exit_net','size'), sum=('exit_net','sum'), mean=('exit_net','mean'))\n",
    "    .reset_index()\n",
    "    .sort_values(['atr_bucket','strategy','exit_reason'])\n",
    ")\n",
    "exit_summary[['sum','mean']] = exit_summary[['sum','mean']].round(2)\n",
    "exit_summary['count'] = exit_summary['count'].astype(int)\n",
    "exit_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de83360d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== ATR帯×戦略×EXIT理由（合計ピボット） ====\n",
    "if 'exit_summary' not in globals():\n",
    "    raise NameError('exit_summary が見つかりません (前セルを実行してください)')\n",
    "exit_pivot = (\n",
    "    exit_summary\n",
    "    .pivot_table(index=['atr_bucket','strategy'], columns='exit_reason', values='sum', fill_value=0, observed=False)\n",
    "    .sort_index()\n",
    "    .round(2)\n",
    ")\n",
    "exit_pivot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bfa5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==== Donchian×ATR×ストラテジーの損益 ====\n",
    "if 'metrics_d' not in globals():\n",
    "    raise NameError('metrics_d が見つかりません (先に ATR×Donchian帯域の損益集計 セルを実行してください)')\n",
    "idx = pd.IndexSlice\n",
    "style = metrics_d.style\n",
    "style = style.format('{:.2f}', subset=idx[:, idx[['sum','mean'], :]])\n",
    "style = style.format('{:d}', subset=idx[:, idx[['count'], :]])\n",
    "style.set_table_attributes('style=\"table-layout: fixed; width: 100%;\"')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb54bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== 例: ATR帯域×戦略の損益集計 ====\n",
    "exits = bt_df[bt_df['event'] == 'EXIT'].copy()\n",
    "exits['atr_entry'] = exits['atr_entry'].astype(float)\n",
    "bins = ATR_BUCKET_BINS\n",
    "labels = ATR_BUCKET_LABELS\n",
    "exits['atr_band'] = pd.cut(exits['atr_entry'], bins=bins, labels=labels, right=False)\n",
    "pivot = exits.pivot_table(index='atr_band', columns='strategy', values='net', aggfunc='sum', fill_value=0, observed=False)\n",
    "pivot = pivot.round(2)\n",
    "pivot.style.format('{:.2f}').set_table_attributes('style=\"table-layout: fixed; width: 100%;\"')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30dbb177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== BT全体指標のサマリ ====\n",
    "bt_exits = bt_df[bt_df['event'] == 'EXIT'].copy()\n",
    "if bt_exits.empty:\n",
    "    raise ValueError('EXITデータが存在しません')\n",
    "bt_exits = bt_exits.sort_values('timestamp')\n",
    "\n",
    "bt_exits['net'] = bt_exits['net'].astype(float)\n",
    "bt_exits['pips'] = bt_exits['pips'].astype(float)\n",
    "\n",
    "total_trades = len(bt_exits)\n",
    "wins = bt_exits['net'] > 0\n",
    "losses = bt_exits['net'] < 0\n",
    "\n",
    "gross_profit = bt_exits.loc[wins, 'net'].sum()\n",
    "gross_loss = bt_exits.loc[losses, 'net'].sum()\n",
    "profit_factor = gross_profit / abs(gross_loss) if gross_loss != 0 else float('inf')\n",
    "win_rate = wins.sum() / total_trades if total_trades else float('nan')\n",
    "\n",
    "avg_win = bt_exits.loc[wins, 'net'].mean() if wins.any() else 0.0\n",
    "avg_loss = bt_exits.loc[losses, 'net'].mean() if losses.any() else 0.0\n",
    "expectancy = bt_exits['net'].mean()\n",
    "\n",
    "# 最大ドローダウンの算出\n",
    "equity_curve = bt_exits['net'].cumsum()\n",
    "equity_curve = pd.concat([pd.Series([0.0]), equity_curve], ignore_index=True)\n",
    "rolling_peak = equity_curve.cummax()\n",
    "drawdown = equity_curve - rolling_peak\n",
    "max_drawdown = drawdown.min()\n",
    "drawdown_pct = drawdown / rolling_peak.replace(0, pd.NA)\n",
    "max_drawdown_pct = drawdown_pct.min()\n",
    "\n",
    "summary = {\n",
    "    'trades': total_trades,\n",
    "    'wins': int(wins.sum()),\n",
    "    'losses': int(losses.sum()),\n",
    "    'win_rate_pct': win_rate * 100,\n",
    "    'gross_profit': gross_profit,\n",
    "    'gross_loss': gross_loss,\n",
    "    'profit_factor': profit_factor,\n",
    "    'avg_win': avg_win,\n",
    "    'avg_loss': avg_loss,\n",
    "    'expectancy': expectancy,\n",
    "    'max_drawdown': max_drawdown,\n",
    "    'max_drawdown_pct': max_drawdown_pct * 100,\n",
    "}\n",
    "\n",
    "label_map = {\n",
    "    'trades': '総トレード数',\n",
    "    'wins': '勝ち回数',\n",
    "    'losses': '負け回数',\n",
    "    'win_rate_pct': '勝率',\n",
    "    'gross_profit': '総利益',\n",
    "    'gross_loss': '総損失',\n",
    "    'profit_factor': 'PF',\n",
    "    'avg_win': '平均利益',\n",
    "    'avg_loss': '平均損失',\n",
    "    'expectancy': '期待値',\n",
    "    'max_drawdown': '最大DD',\n",
    "    'max_drawdown_pct': '最大DD(%)',\n",
    "}\n",
    "percent_keys = {'win_rate_pct', 'max_drawdown_pct'}\n",
    "value_keys = {'profit_factor', 'avg_win', 'avg_loss', 'expectancy', 'gross_profit', 'gross_loss', 'max_drawdown'}\n",
    "\n",
    "rows = []\n",
    "for key in label_map:\n",
    "    value = summary.get(key)\n",
    "    if pd.isna(value):\n",
    "        display_value = 'NaN'\n",
    "    elif key in percent_keys:\n",
    "        display_value = f\"{value:.2f}%\"\n",
    "    elif key in value_keys:\n",
    "        display_value = f\"{value:.2f}\"\n",
    "    else:\n",
    "        display_value = f\"{int(value)}\"\n",
    "    rows.append({'指標': label_map[key], '値': display_value})\n",
    "\n",
    "summary_df = pd.DataFrame(rows)\n",
    "summary_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f0c996b5434da2ad130e5ff3a3effe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== 戦略別BT指標サマリ ====\n",
    "bt_exits = bt_df[bt_df['event'] == 'EXIT'].copy()\n",
    "if bt_exits.empty:\n",
    "    raise ValueError('EXITデータが存在しません')\n",
    "if 'strategy' not in bt_exits.columns:\n",
    "    raise KeyError('strategy 列が存在しません')\n",
    "\n",
    "bt_exits['net'] = bt_exits['net'].astype(float)\n",
    "\n",
    "def summarize_group(group):\n",
    "    total = len(group)\n",
    "    wins = group['net'] > 0\n",
    "    losses = group['net'] < 0\n",
    "    gross_profit = group.loc[wins, 'net'].sum()\n",
    "    gross_loss = group.loc[losses, 'net'].sum()\n",
    "    profit_factor = gross_profit / abs(gross_loss) if gross_loss != 0 else float('inf')\n",
    "    win_rate = wins.sum() / total if total else float('nan')\n",
    "    avg_win = group.loc[wins, 'net'].mean() if wins.any() else 0.0\n",
    "    avg_loss = group.loc[losses, 'net'].mean() if losses.any() else 0.0\n",
    "    expectancy = group['net'].mean()\n",
    "    return pd.Series({\n",
    "        'trades': total,\n",
    "        'wins': int(wins.sum()),\n",
    "        'losses': int(losses.sum()),\n",
    "        'win_rate_pct': win_rate * 100,\n",
    "        'profit_factor': profit_factor,\n",
    "        'avg_win': avg_win,\n",
    "        'avg_loss': avg_loss,\n",
    "        'expectancy': expectancy,\n",
    "    })\n",
    "\n",
    "strategy_summary = (\n",
    "    bt_exits.groupby('strategy', group_keys=False)\n",
    "    .apply(summarize_group)\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "rename_map = {\n",
    "    'strategy': 'Strategy',\n",
    "    'trades': 'Trades',\n",
    "    'wins': 'Wins',\n",
    "    'losses': 'Losses',\n",
    "    'win_rate_pct': 'Win Rate (%)',\n",
    "    'profit_factor': 'PF',\n",
    "    'avg_win': 'Avg Win',\n",
    "    'avg_loss': 'Avg Loss',\n",
    "    'expectancy': 'Expectancy',\n",
    "}\n",
    "strategy_summary = strategy_summary.rename(columns=rename_map)\n",
    "\n",
    "format_dict = {\n",
    "    'Win Rate (%)': '{:.2f}',\n",
    "    'PF': '{:.2f}',\n",
    "    'Avg Win': '{:.2f}',\n",
    "    'Avg Loss': '{:.2f}',\n",
    "    'Expectancy': '{:.2f}',\n",
    "}\n",
    "strategy_summary.style.format(format_dict).hide(axis=\"index\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679106af",
   "metadata": {},
   "source": [
    "## TODO\n",
    "- 週次/日次での State×BT 結合関数を関数化する\n",
    "- 追加の特徴量（ATR増減、セッションフラグなど）を派生列として定義する\n",
    "- ML モデル用に `merged` から特徴量テーブルを作成する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999e4718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== ノート別名保存（BTファイル名付き） ====\n",
    "import nbformat\n",
    "if 'bt_path' not in globals():\n",
    "    raise NameError('bt_path が未定義です (データ読み込みセルを先に実行してください)')\n",
    "base_name = bt_path.stem.replace(' ', '_')\n",
    "dest_path = OUTPUT_NOTEBOOK_DIR / f\"state_bt_analysis_{base_name}.ipynb\"\n",
    "with CURRENT_NOTEBOOK_PATH.open('r', encoding='utf-8') as fh:\n",
    "    nb_data = nbformat.read(fh, as_version=4)\n",
    "nbformat.write(nb_data, str(dest_path))\n",
    "print(f'Saved notebook copy to: {dest_path}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "YoYoEA ML",
   "language": "python",
   "name": "yoyoea-ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
